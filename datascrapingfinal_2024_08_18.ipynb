{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMul9FqWjOnVlXyVhia/qEF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thinpine/pure-tv/blob/main/datascrapingfinal_2024_08_18.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Trials with fake user agent (failed)**"
      ],
      "metadata": {
        "id": "uNCx0HF2g-3_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xX_REfqsLBev",
        "outputId": "b198eb1b-e1f1-4358-ce6f-3be05946feb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fake-useragent\n",
            "  Downloading fake_useragent-1.5.1-py3-none-any.whl.metadata (15 kB)\n",
            "Downloading fake_useragent-1.5.1-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: fake-useragent\n",
            "Successfully installed fake-useragent-1.5.1\n"
          ]
        }
      ],
      "source": [
        "pip install fake-useragent"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the required libraries\n",
        "\n",
        "import requests\n",
        "\n",
        "from fake_useragent import UserAgent\n",
        "\n",
        "\n",
        "\n",
        "# Instantiate the UserAgent class\n",
        "\n",
        "ua = UserAgent()\n",
        "\n",
        "\n",
        "\n",
        "# Get random user agents\n",
        "\n",
        "random_ua = ua.random\n",
        "\n",
        "\n",
        "\n",
        "# Specify the request URL\n",
        "\n",
        "url = 'https://www.imdb.com/search/title/?title_type=tv_series&release_date=2019-01-01,2024-07-01&genres=!documentary,!short&countries=TR&sort=release_date,asc'\n",
        "\n",
        "\n",
        "\n",
        "# Pass the random user agents to the user-agent headers\n",
        "\n",
        "request_headers = {\n",
        "\n",
        "    'user-agent': random_ua\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "# Make a get request to the URL and get the response\n",
        "\n",
        "response = requests.get(url, headers= request_headers)\n",
        "\n",
        "\n",
        "\n",
        "# Resolve response and print the user agent information\n",
        "\n",
        "if response.status_code == 200:\n",
        "\n",
        "    print(response.request.headers['User-Agent'])\n",
        "\n",
        "else:\n",
        "\n",
        "    print(response.status_code)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pu8pvgdJLFm6",
        "outputId": "df443b05-0c7c-4398-8ead-71e7c578eb7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Extracts IMDB ID's from IMDB html text**"
      ],
      "metadata": {
        "id": "Aersn5grhIoF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_titles(file_path):\n",
        "    titles = []  # To store the extracted titles\n",
        "\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        data = file.read()\n",
        "\n",
        "    start = 0  # Position to start searching for the next 'title/tt'\n",
        "    while True:\n",
        "        # Find the next occurrence of 'title/tt'\n",
        "        start = data.find('title/tt', start)\n",
        "        if start == -1:  # If 'title/tt' is not found, stop the loop\n",
        "            break\n",
        "\n",
        "        # Move the position to after 'title/tt'\n",
        "        start += len('title/tt')\n",
        "\n",
        "        # Find the position of the next '/'\n",
        "        end = data.find('/', start)\n",
        "\n",
        "        # Extract the string from 'tt' to the next '/'\n",
        "        if end != -1:\n",
        "            titles.append('tt' + data[start:end])\n",
        "\n",
        "    return titles\n",
        "\n",
        "# Example usage\n",
        "file_path = '/content/fullhtmltext_filtered.txt'\n",
        "titles_array = extract_titles(file_path)\n",
        "print(titles_array) #Array contains two instances of every IMDB ID, each being back to back.\n",
        "print(len(titles_array)/2) #Number of shows\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddHgJ9PSYScL",
        "outputId": "31b0b4ac-d8e6-4cc3-9650-37c69cd09086"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['tt9520396', 'tt9520396', 'tt11282156', 'tt11282156', 'tt11637968', 'tt11637968', 'tt9471962', 'tt9471962', 'tt14864648', 'tt14864648', 'tt9529618', 'tt9529618', 'tt9529892', 'tt9529892', 'tt9525880', 'tt9525880', 'tt9355244', 'tt9355244', 'tt9529500', 'tt9529500', 'tt9826628', 'tt9826628', 'tt16711822', 'tt16711822', 'tt19849996', 'tt19849996', 'tt9667744', 'tt9667744', 'tt25148102', 'tt25148102', 'tt9540596', 'tt9540596', 'tt9808672', 'tt9808672', 'tt9721776', 'tt9721776', 'tt9732208', 'tt9732208', 'tt9910728', 'tt9910728', 'tt9915022', 'tt9915022', 'tt10137654', 'tt10137654', 'tt10098792', 'tt10098792', 'tt9477680', 'tt9477680', 'tt10147676', 'tt10147676', 'tt10278814', 'tt10278814', 'tt10105930', 'tt10105930', 'tt31630338', 'tt31630338', 'tt10319992', 'tt10319992', 'tt10376348', 'tt10376348', 'tt14055540', 'tt14055540', 'tt10377430', 'tt10377430', 'tt10324306', 'tt10324306', 'tt10374050', 'tt10374050', 'tt10319866', 'tt10319866', 'tt8846682', 'tt8846682', 'tt10611748', 'tt10611748', 'tt11224026', 'tt11224026', 'tt10963784', 'tt10963784', 'tt10689840', 'tt10689840', 'tt10850402', 'tt10850402', 'tt10855046', 'tt10855046', 'tt10723804', 'tt10723804', 'tt10476544', 'tt10476544', 'tt10682186', 'tt10682186', 'tt10882988', 'tt10882988', 'tt11041664', 'tt11041664', 'tt10941792', 'tt10941792', 'tt11690036', 'tt11690036', 'tt11039324', 'tt11039324', 'tt10924104', 'tt10924104', 'tt11006992', 'tt11006992', 'tt11231274', 'tt11231274', 'tt11007006', 'tt11007006', 'tt11093718', 'tt11093718', 'tt11174344', 'tt11174344', 'tt11149738', 'tt11149738', 'tt11256614', 'tt11256614', 'tt11256260', 'tt11256260', 'tt13836582', 'tt13836582', 'tt11100380', 'tt11100380', 'tt10075318', 'tt10075318', 'tt10421058', 'tt10421058', 'tt10243210', 'tt10243210', 'tt8785126', 'tt8785126', 'tt24244126', 'tt24244126', 'tt18377768', 'tt18377768', 'tt10374692', 'tt10374692', 'tt20221056', 'tt20221056', 'tt9543192', 'tt9543192', 'tt16342206', 'tt16342206', 'tt11519740', 'tt11519740', 'tt11051886', 'tt11051886', 'tt11426542', 'tt11426542', 'tt11138216', 'tt11138216', 'tt11561800', 'tt11561800', 'tt11667660', 'tt11667660', 'tt10476258', 'tt10476258', 'tt11956992', 'tt11956992', 'tt16603226', 'tt16603226', 'tt11789868', 'tt11789868', 'tt11755606', 'tt11755606', 'tt11790130', 'tt11790130', 'tt19731330', 'tt19731330', 'tt11598800', 'tt11598800', 'tt31029270', 'tt31029270', 'tt12100754', 'tt12100754', 'tt11232670', 'tt11232670', 'tt14748372', 'tt14748372', 'tt14411824', 'tt14411824', 'tt12171672', 'tt12171672', 'tt12187550', 'tt12187550', 'tt10516352', 'tt10516352', 'tt12418160', 'tt12418160', 'tt13981320', 'tt13981320', 'tt12496588', 'tt12496588', 'tt12509860', 'tt12509860', 'tt12453442', 'tt12453442', 'tt12928068', 'tt12928068', 'tt12439466', 'tt12439466', 'tt12498170', 'tt12498170', 'tt15018666', 'tt15018666', 'tt13027752', 'tt13027752', 'tt12531662', 'tt12531662', 'tt12844732', 'tt12844732', 'tt12844722', 'tt12844722', 'tt11896074', 'tt11896074', 'tt12687036', 'tt12687036', 'tt12531682', 'tt12531682', 'tt12562262', 'tt12562262', 'tt12466076', 'tt12466076', 'tt13074816', 'tt13074816', 'tt12872494', 'tt12872494', 'tt12735946', 'tt12735946', 'tt18273934', 'tt18273934', 'tt12694046', 'tt12694046', 'tt12632132', 'tt12632132', 'tt12879200', 'tt12879200', 'tt13001132', 'tt13001132', 'tt12872866', 'tt12872866', 'tt12872884', 'tt12872884', 'tt15727690', 'tt15727690', 'tt13286658', 'tt13286658', 'tt11450050', 'tt11450050', 'tt12872898', 'tt12872898', 'tt11301642', 'tt11301642', 'tt18245418', 'tt18245418', 'tt13286144', 'tt13286144', 'tt13021414', 'tt13021414', 'tt12687768', 'tt12687768', 'tt13837004', 'tt13837004', 'tt12916174', 'tt12916174', 'tt14465838', 'tt14465838', 'tt13318074', 'tt13318074', 'tt13470984', 'tt13470984', 'tt13743802', 'tt13743802', 'tt12718188', 'tt12718188', 'tt13760838', 'tt13760838', 'tt16384792', 'tt16384792', 'tt16532070', 'tt16532070', 'tt13675832', 'tt13675832', 'tt13322702', 'tt13322702', 'tt13437388', 'tt13437388', 'tt13528822', 'tt13528822', 'tt12858840', 'tt12858840', 'tt13583468', 'tt13583468', 'tt12779734', 'tt12779734', 'tt13364024', 'tt13364024', 'tt13247296', 'tt13247296', 'tt13728634', 'tt13728634', 'tt13691420', 'tt13691420', 'tt13723198', 'tt13723198', 'tt13745588', 'tt13745588', 'tt13731738', 'tt13731738', 'tt13691134', 'tt13691134', 'tt13760850', 'tt13760850', 'tt12694140', 'tt12694140', 'tt13793502', 'tt13793502', 'tt13731764', 'tt13731764', 'tt11617848', 'tt11617848', 'tt12694080', 'tt12694080', 'tt14132810', 'tt14132810', 'tt14183208', 'tt14183208', 'tt13856832', 'tt13856832', 'tt14045562', 'tt14045562', 'tt16051202', 'tt16051202', 'tt12929044', 'tt12929044', 'tt11437496', 'tt11437496', 'tt14024714', 'tt14024714', 'tt13550498', 'tt13550498', 'tt13726244', 'tt13726244', 'tt14044824', 'tt14044824', 'tt20843062', 'tt20843062', 'tt13562418', 'tt13562418', 'tt13708016', 'tt13708016', 'tt13923096', 'tt13923096', 'tt14183052', 'tt14183052', 'tt13116708', 'tt13116708', 'tt13381804', 'tt13381804', 'tt14193896', 'tt14193896', 'tt13503990', 'tt13503990', 'tt14014086', 'tt14014086', 'tt14385558', 'tt14385558', 'tt14571768', 'tt14571768', 'tt13833934', 'tt13833934', 'tt13748376', 'tt13748376', 'tt14625796', 'tt14625796', 'tt14265894', 'tt14265894', 'tt13592218', 'tt13592218', 'tt32315370', 'tt32315370', 'tt13923144', 'tt13923144', 'tt11961378', 'tt11961378', 'tt14661936', 'tt14661936', 'tt14438536', 'tt14438536', 'tt14872600', 'tt14872600', 'tt14344266', 'tt14344266', 'tt14368816', 'tt14368816', 'tt14650226', 'tt14650226', 'tt13156646', 'tt13156646', 'tt14183324', 'tt14183324', 'tt14183290', 'tt14183290', 'tt14639548', 'tt14639548', 'tt14411816', 'tt14411816', 'tt14411808', 'tt14411808', 'tt14814006', 'tt14814006', 'tt14588158', 'tt14588158', 'tt15732882', 'tt15732882', 'tt14395722', 'tt14395722', 'tt13717946', 'tt13717946', 'tt13856804', 'tt13856804', 'tt14342244', 'tt14342244', 'tt14404174', 'tt14404174', 'tt15568716', 'tt15568716', 'tt15033694', 'tt15033694', 'tt14551046', 'tt14551046', 'tt14364684', 'tt14364684', 'tt14827134', 'tt14827134', 'tt18345426', 'tt18345426', 'tt18569946', 'tt18569946', 'tt15204372', 'tt15204372', 'tt15231136', 'tt15231136', 'tt14753620', 'tt14753620', 'tt13856758', 'tt13856758', 'tt14667582', 'tt14667582', 'tt14473896', 'tt14473896', 'tt14183314', 'tt14183314', 'tt12979628', 'tt12979628', 'tt15404360', 'tt15404360', 'tt15023948', 'tt15023948', 'tt12695420', 'tt12695420', 'tt13587828', 'tt13587828', 'tt16226462', 'tt16226462', 'tt14715548', 'tt14715548', 'tt18345484', 'tt18345484', 'tt15680438', 'tt15680438', 'tt14032126', 'tt14032126', 'tt15281706', 'tt15281706', 'tt15471776', 'tt15471776', 'tt14810626', 'tt14810626', 'tt15471788', 'tt15471788', 'tt15441312', 'tt15441312', 'tt13317582', 'tt13317582', 'tt15192718', 'tt15192718', 'tt15087526', 'tt15087526', 'tt12934652', 'tt12934652', 'tt15443084', 'tt15443084', 'tt16245788', 'tt16245788', 'tt14779804', 'tt14779804', 'tt14433846', 'tt14433846', 'tt15665202', 'tt15665202', 'tt15471722', 'tt15471722', 'tt15793068', 'tt15793068', 'tt14898744', 'tt14898744', 'tt13868934', 'tt13868934', 'tt27835210', 'tt27835210', 'tt14183342', 'tt14183342', 'tt17044638', 'tt17044638', 'tt15299654', 'tt15299654', 'tt15715130', 'tt15715130', 'tt14639598', 'tt14639598', 'tt17422182', 'tt17422182', 'tt16452902', 'tt16452902', 'tt14368830', 'tt14368830', 'tt19850920', 'tt19850920', 'tt16711824', 'tt16711824', 'tt16539540', 'tt16539540', 'tt16428772', 'tt16428772', 'tt16162676', 'tt16162676', 'tt16259122', 'tt16259122', 'tt16259110', 'tt16259110', 'tt13317508', 'tt13317508', 'tt13328796', 'tt13328796', 'tt16733832', 'tt16733832', 'tt16538982', 'tt16538982', 'tt18816456', 'tt18816456', 'tt13317478', 'tt13317478', 'tt17678828', 'tt17678828', 'tt29142261', 'tt29142261', 'tt17678832', 'tt17678832', 'tt17678840', 'tt17678840', 'tt18247270', 'tt18247270', 'tt13317454', 'tt13317454', 'tt17678824', 'tt17678824', 'tt19394340', 'tt19394340', 'tt18644688', 'tt18644688', 'tt13238304', 'tt13238304', 'tt32175111', 'tt32175111', 'tt13352998', 'tt13352998', 'tt19852660', 'tt19852660', 'tt19246566', 'tt19246566', 'tt13323566', 'tt13323566', 'tt19394272', 'tt19394272', 'tt19410124', 'tt19410124', 'tt15561916', 'tt15561916', 'tt16420408', 'tt16420408', 'tt21376364', 'tt21376364', 'tt19850916', 'tt19850916', 'tt19394290', 'tt19394290', 'tt20248548', 'tt20248548', 'tt19410126', 'tt19410126', 'tt21143150', 'tt21143150', 'tt19759234', 'tt19759234', 'tt20319272', 'tt20319272', 'tt19768226', 'tt19768226', 'tt13026866', 'tt13026866', 'tt20248478', 'tt20248478', 'tt20319266', 'tt20319266', 'tt20603316', 'tt20603316', 'tt20835764', 'tt20835764', 'tt21342612', 'tt21342612', 'tt14899624', 'tt14899624', 'tt22071500', 'tt22071500', 'tt19383446', 'tt19383446', 'tt21105044', 'tt21105044', 'tt32358077', 'tt32358077', 'tt17678852', 'tt17678852', 'tt20319260', 'tt20319260', 'tt20248498', 'tt20248498', 'tt21257114', 'tt21257114', 'tt19496062', 'tt19496062', 'tt28213749', 'tt28213749', 'tt21105088', 'tt21105088', 'tt21194680', 'tt21194680', 'tt21922096', 'tt21922096', 'tt21435250', 'tt21435250', 'tt21029674', 'tt21029674', 'tt32174797', 'tt32174797', 'tt20833312', 'tt20833312', 'tt22770630', 'tt22770630', 'tt21766660', 'tt21766660', 'tt19246582', 'tt19246582', 'tt14486722', 'tt14486722', 'tt28213608', 'tt28213608', 'tt21741266', 'tt21741266', 'tt21268566', 'tt21268566', 'tt23016854', 'tt23016854', 'tt21385714', 'tt21385714', 'tt21764074', 'tt21764074', 'tt22044970', 'tt22044970', 'tt21874026', 'tt21874026', 'tt21874038', 'tt21874038', 'tt19394330', 'tt19394330', 'tt22497918', 'tt22497918', 'tt22325952', 'tt22325952', 'tt22693974', 'tt22693974', 'tt22467674', 'tt22467674', 'tt23791028', 'tt23791028', 'tt21095396', 'tt21095396', 'tt27505723', 'tt27505723', 'tt22037042', 'tt22037042', 'tt21741256', 'tt21741256', 'tt22869654', 'tt22869654', 'tt26428591', 'tt26428591', 'tt21856826', 'tt21856826', 'tt29540777', 'tt29540777', 'tt26685732', 'tt26685732', 'tt23807114', 'tt23807114', 'tt22726060', 'tt22726060', 'tt22719788', 'tt22719788', 'tt25728426', 'tt25728426', 'tt22727856', 'tt22727856', 'tt21268616', 'tt21268616', 'tt24022460', 'tt24022460', 'tt22806544', 'tt22806544', 'tt16913068', 'tt16913068', 'tt25728454', 'tt25728454', 'tt22718792', 'tt22718792', 'tt24224504', 'tt24224504', 'tt21874046', 'tt21874046', 'tt25011148', 'tt25011148', 'tt21764804', 'tt21764804', 'tt28109788', 'tt28109788', 'tt26547403', 'tt26547403', 'tt32187285', 'tt32187285', 'tt27123253', 'tt27123253', 'tt32314581', 'tt32314581', 'tt27204916', 'tt27204916', 'tt26083408', 'tt26083408', 'tt22467658', 'tt22467658', 'tt16163746', 'tt16163746', 'tt20196198', 'tt20196198', 'tt22728026', 'tt22728026', 'tt26653283', 'tt26653283', 'tt19368600', 'tt19368600', 'tt28644679', 'tt28644679', 'tt15473010', 'tt15473010', 'tt27843403', 'tt27843403', 'tt14533598', 'tt14533598', 'tt21279302', 'tt21279302', 'tt21095420', 'tt21095420', 'tt27795928', 'tt27795928', 'tt23459414', 'tt23459414', 'tt21345412', 'tt21345412', 'tt23813378', 'tt23813378', 'tt21268600', 'tt21268600', 'tt23322924', 'tt23322924', 'tt12512714', 'tt12512714', 'tt27032626', 'tt27032626', 'tt26625889', 'tt26625889', 'tt23109230', 'tt23109230', 'tt22394746', 'tt22394746', 'tt26345503', 'tt26345503', 'tt23322920', 'tt23322920', 'tt27250379', 'tt27250379', 'tt27694624', 'tt27694624', 'tt27747195', 'tt27747195', 'tt23108508', 'tt23108508', 'tt14107656', 'tt14107656', 'tt22394752', 'tt22394752', 'tt21308714', 'tt21308714', 'tt27827768', 'tt27827768', 'tt14533970', 'tt14533970', 'tt28075973', 'tt28075973', 'tt27739128', 'tt27739128', 'tt28131349', 'tt28131349', 'tt27874348', 'tt27874348', 'tt27494111', 'tt27494111', 'tt19246424', 'tt19246424', 'tt27478354', 'tt27478354', 'tt28228754', 'tt28228754', 'tt28146056', 'tt28146056', 'tt28297345', 'tt28297345', 'tt23032590', 'tt23032590', 'tt28334660', 'tt28334660', 'tt28638980', 'tt28638980', 'tt32338215', 'tt32338215', 'tt31182969', 'tt31182969', 'tt28355499', 'tt28355499', 'tt22869606', 'tt22869606', 'tt27796193', 'tt27796193', 'tt22727518', 'tt22727518', 'tt28334633', 'tt28334633', 'tt19636762', 'tt19636762', 'tt29258720', 'tt29258720', 'tt23396714', 'tt23396714', 'tt28380138', 'tt28380138', 'tt28780239', 'tt28780239', 'tt28334630', 'tt28334630', 'tt29425854', 'tt29425854', 'tt30025590', 'tt30025590', 'tt22642898', 'tt22642898', 'tt21279294', 'tt21279294', 'tt27796339', 'tt27796339', 'tt28379984', 'tt28379984', 'tt29626178', 'tt29626178', 'tt29291631', 'tt29291631', 'tt21856856', 'tt21856856', 'tt21095400', 'tt21095400', 'tt30225782', 'tt30225782', 'tt29731276', 'tt29731276', 'tt29926954', 'tt29926954', 'tt28334662', 'tt28334662', 'tt30054237', 'tt30054237', 'tt27032643', 'tt27032643', 'tt15676170', 'tt15676170', 'tt23865478', 'tt23865478', 'tt32857277', 'tt32857277', 'tt28132667', 'tt28132667', 'tt30690005', 'tt30690005', 'tt30872765', 'tt30872765', 'tt29621957', 'tt29621957', 'tt26760483', 'tt26760483', 'tt30461250', 'tt30461250', 'tt30825199', 'tt30825199', 'tt30799082', 'tt30799082', 'tt31027788', 'tt31027788', 'tt30959036', 'tt30959036', 'tt32213510', 'tt32213510', 'tt32376663', 'tt32376663', 'tt31042239', 'tt31042239', 'tt31012986', 'tt31012986', 'tt31123801', 'tt31123801', 'tt31064976', 'tt31064976', 'tt31410134', 'tt31410134', 'tt14014078', 'tt14014078', 'tt31409605', 'tt31409605', 'tt31323988', 'tt31323988', 'tt31064918', 'tt31064918', 'tt31049778', 'tt31049778', 'tt31315003', 'tt31315003', 'tt31639770', 'tt31639770', 'tt31846917', 'tt31846917', 'tt32105443', 'tt32105443', 'tt31704015', 'tt31704015', 'tt28267514', 'tt28267514', 'tt21308746', 'tt21308746', 'tt32345015', 'tt32345015']\n",
            "487.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Code I ended up with**"
      ],
      "metadata": {
        "id": "o8Ue-fz0qjZp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "def extract_titles(file_path):\n",
        "    titles = []  # To store the extracted titles\n",
        "\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        data = file.read()\n",
        "\n",
        "    start = 0  # Position to start searching for the next 'title/tt'\n",
        "    while True:\n",
        "        # Find the next occurrence of 'title/tt'\n",
        "        start = data.find('title/tt', start)\n",
        "        if start == -1:  # If 'title/tt' is not found, stop the loop\n",
        "            break\n",
        "\n",
        "        # Move the position to after 'title/tt'\n",
        "        start += len('title/tt')\n",
        "\n",
        "        # Find the position of the next '/'\n",
        "        end = data.find('/', start)\n",
        "\n",
        "        # Extract the string from 'tt' to the next '/'\n",
        "        if end != -1:\n",
        "            titles.append('tt' + data[start:end])\n",
        "\n",
        "    return titles\n",
        "\n",
        "# Example usage\n",
        "file_path = '/content/fullhtmltext_filtered.txt'\n",
        "imdb_ids = extract_titles(file_path)\n",
        "\n",
        "\n",
        "def scrape_imdb_data(imdb_ids):\n",
        "    # List to store the scraped data\n",
        "    scraped_data = []\n",
        "\n",
        "    # Base URL for IMDb\n",
        "    base_url = \"https://www.imdb.com/title/\"\n",
        "\n",
        "    for i in range(0, len(imdb_ids), 2):\n",
        "        # Create the URL for the IMDb page\n",
        "        url = base_url + imdb_ids[i]\n",
        "\n",
        "        # Send an HTTP GET request to fetch the HTML content of the page\n",
        "        response = requests.get(url)\n",
        "        if response.status_code != 200:\n",
        "            print(f\"Failed to retrieve {imdb_ids[i]}\")\n",
        "            continue\n",
        "\n",
        "        # Parse the HTML content using BeautifulSoup\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Extract relevant data (example fields)\n",
        "        try:\n",
        "            # Get the title of the movie/series\n",
        "            title = soup.find('h1').text.strip()\n",
        "\n",
        "            # Get the start and end dates (if available)\n",
        "            date_range = soup.find('span', {'id': 'titleYear'}).text.strip() if soup.find('span', {'id': 'titleYear'}) else \"N/A\"\n",
        "\n",
        "            # Get the number of episodes (if it's a series)\n",
        "            episodes = soup.find('span', text='Episodes:').next_sibling.strip() if soup.find('span', text='Episodes:') else \"N/A\"\n",
        "\n",
        "            # Get the parental certificate or guide\n",
        "            certificate = soup.find('span', {'class': 'certificate'}).text.strip() if soup.find('span', {'class': 'certificate'}) else \"N/A\"\n",
        "\n",
        "            # Get the stars (actors) listed\n",
        "            stars_section = soup.find_all('a', href=lambda href: href and \"/name/\" in href)\n",
        "            stars = ', '.join([star.text.strip() for star in stars_section[:5]])  # Limiting to the first 5 stars\n",
        "\n",
        "            # Add the scraped data to the list\n",
        "            scraped_data.append([imdb_ids[i], title, date_range, episodes, certificate, stars])\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error scraping {imdb_ids[i]}: {e}\")\n",
        "\n",
        "    return scraped_data\n",
        "\n",
        "def write_to_csv(scraped_data, output_file):\n",
        "    # Define the headers for the CSV file\n",
        "    headers = [\"IMDB ID\", \"Title\", \"Date Range\", \"Episode Count\", \"Certificate\", \"Stars\"]\n",
        "\n",
        "    # Write the data to a CSV file\n",
        "    with open(output_file, 'w', newline='', encoding='utf-8') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow(headers)\n",
        "        writer.writerows(scraped_data)\n",
        "\n",
        "# Example usage\n",
        "#imdb_ids = [\"tt0111161\", \"tt0133093\"]  # Replace with your list of IMDb IDs\n",
        "scraped_data = scrape_imdb_data(imdb_ids)\n",
        "write_to_csv(scraped_data, 'imdb_scraped_data.csv')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "N1ngkqMDmV5y",
        "outputId": "3f2d14df-d8d2-4c87-81c2-ae8e79e22e45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to retrieve tt9520396\n",
            "Failed to retrieve tt11282156\n",
            "Failed to retrieve tt11637968\n",
            "Failed to retrieve tt9471962\n",
            "Failed to retrieve tt14864648\n",
            "Failed to retrieve tt9529618\n",
            "Failed to retrieve tt9529892\n",
            "Failed to retrieve tt9525880\n",
            "Failed to retrieve tt9355244\n",
            "Failed to retrieve tt9529500\n",
            "Failed to retrieve tt9826628\n",
            "Failed to retrieve tt16711822\n",
            "Failed to retrieve tt19849996\n",
            "Failed to retrieve tt9667744\n",
            "Failed to retrieve tt25148102\n",
            "Failed to retrieve tt9540596\n",
            "Failed to retrieve tt9808672\n",
            "Failed to retrieve tt9721776\n",
            "Failed to retrieve tt9732208\n",
            "Failed to retrieve tt9910728\n",
            "Failed to retrieve tt9915022\n",
            "Failed to retrieve tt10137654\n",
            "Failed to retrieve tt10098792\n",
            "Failed to retrieve tt9477680\n",
            "Failed to retrieve tt10147676\n",
            "Failed to retrieve tt10278814\n",
            "Failed to retrieve tt10105930\n",
            "Failed to retrieve tt31630338\n",
            "Failed to retrieve tt10319992\n",
            "Failed to retrieve tt10376348\n",
            "Failed to retrieve tt14055540\n",
            "Failed to retrieve tt10377430\n",
            "Failed to retrieve tt10324306\n",
            "Failed to retrieve tt10374050\n",
            "Failed to retrieve tt10319866\n",
            "Failed to retrieve tt8846682\n",
            "Failed to retrieve tt10611748\n",
            "Failed to retrieve tt11224026\n",
            "Failed to retrieve tt10963784\n",
            "Failed to retrieve tt10689840\n",
            "Failed to retrieve tt10850402\n",
            "Failed to retrieve tt10855046\n",
            "Failed to retrieve tt10723804\n",
            "Failed to retrieve tt10476544\n",
            "Failed to retrieve tt10682186\n",
            "Failed to retrieve tt10882988\n",
            "Failed to retrieve tt11041664\n",
            "Failed to retrieve tt10941792\n",
            "Failed to retrieve tt11690036\n",
            "Failed to retrieve tt11039324\n",
            "Failed to retrieve tt10924104\n",
            "Failed to retrieve tt11006992\n",
            "Failed to retrieve tt11231274\n",
            "Failed to retrieve tt11007006\n",
            "Failed to retrieve tt11093718\n",
            "Failed to retrieve tt11174344\n",
            "Failed to retrieve tt11149738\n",
            "Failed to retrieve tt11256614\n",
            "Failed to retrieve tt11256260\n",
            "Failed to retrieve tt13836582\n",
            "Failed to retrieve tt11100380\n",
            "Failed to retrieve tt10075318\n",
            "Failed to retrieve tt10421058\n",
            "Failed to retrieve tt10243210\n",
            "Failed to retrieve tt8785126\n",
            "Failed to retrieve tt24244126\n",
            "Failed to retrieve tt18377768\n",
            "Failed to retrieve tt10374692\n",
            "Failed to retrieve tt20221056\n",
            "Failed to retrieve tt9543192\n",
            "Failed to retrieve tt16342206\n",
            "Failed to retrieve tt11519740\n",
            "Failed to retrieve tt11051886\n",
            "Failed to retrieve tt11426542\n",
            "Failed to retrieve tt11138216\n",
            "Failed to retrieve tt11561800\n",
            "Failed to retrieve tt11667660\n",
            "Failed to retrieve tt10476258\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-d059219c2a07>\u001b[0m in \u001b[0;36m<cell line: 92>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;31m# Example usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;31m#imdb_ids = [\"tt0111161\", \"tt0133093\"]  # Replace with your list of IMDb IDs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m \u001b[0mscraped_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscrape_imdb_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimdb_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0mwrite_to_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscraped_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'imdb_scraped_data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-d059219c2a07>\u001b[0m in \u001b[0;36mscrape_imdb_data\u001b[0;34m(imdb_ids)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m# Send an HTTP GET request to fetch the HTML content of the page\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Failed to retrieve {imdb_ids[i]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \"\"\"\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"get\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    668\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    792\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;31m# Receive the response from the server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1303\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1157\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **The code that can bypass 'Forbidden 403'**"
      ],
      "metadata": {
        "id": "TcTAie7cqm-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import random\n",
        "\n",
        "\n",
        "# crawl IMDB Top 250 and randomly select a movie\n",
        "URL = 'https://www.imdb.com/search/title/?title_type=tv_series&release_date=2019-01-01,2024-07-01&genres=!documentary,!short,!game-show,!reality-tv,!talk-show&countries=TR&sort=release_date,asc'\n",
        "#response = requests.get(URL,  headers={\"User-Agent\": \"Chrome\"})\n",
        "response = requests.get(URL,  headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
        "\n",
        "with open(\"hi.html\", \"w\") as f:\n",
        "    f.write(response.text)\n",
        "\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "links = [i for i in soup.find_all(\"a\", {\"class\":\"ipc-title-link-wrapper\"}) if '/title/' in i['href']]\n",
        "for i in range(25):\n",
        "  selected_movie = links[i]\n",
        "  print('http://www.imdb.com' + selected_movie['href'])\n",
        "  print(selected_movie.text)"
      ],
      "metadata": {
        "id": "8gZNcZisqnPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **The combined + enhanced code**"
      ],
      "metadata": {
        "id": "_0cwik92qsAK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "\n",
        "def extract_titles(file_path):\n",
        "    titles = []  # To store the extracted titles\n",
        "\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        data = file.read()\n",
        "\n",
        "    start = 0  # Position to start searching for the next 'title/tt'\n",
        "    while True:\n",
        "        # Find the next occurrence of 'title/tt'\n",
        "        start = data.find('title/tt', start)\n",
        "        if start == -1:  # If 'title/tt' is not found, stop the loop\n",
        "            break\n",
        "\n",
        "        # Move the position to after 'title/tt'\n",
        "        start += len('title/tt')\n",
        "\n",
        "        # Find the position of the next '/'\n",
        "        end = data.find('/', start)\n",
        "\n",
        "        # Extract the string from 'tt' to the next '/'\n",
        "        if end != -1:\n",
        "            titles.append('tt' + data[start:end])\n",
        "\n",
        "    return titles\n",
        "\n",
        "# Example usage\n",
        "file_path = '/content/fullhtmltext_filtered.txt'\n",
        "imdb_ids = extract_titles(file_path)\n",
        "\n",
        "\n",
        "#Function to retrieve Parents Guide information\n",
        "\n",
        "\"\"\"\n",
        "def get_parents_guide_violence(imdb_id, headers):\n",
        "    base_url = f\"https://www.imdb.com/title/{imdb_id}/\"\n",
        "    response = requests.get(base_url, headers=headers)\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Failed to retrieve {imdb_id}\")\n",
        "        return \"N/A\"\n",
        "\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Find the link to the Parents Guide page\n",
        "    parents_guide_link = soup.find('a', href=lambda href: href and '/parentalguide' in href)\n",
        "    if not parents_guide_link:\n",
        "        return \"N/A\"\n",
        "\n",
        "    # Extract the full URL for the Parents Guide page\n",
        "    parents_guide_url = \"https://www.imdb.com\" + parents_guide_link['href']\n",
        "\n",
        "    # Now send a request to the Parents Guide page\n",
        "    guide_response = requests.get(parents_guide_url, headers=headers)\n",
        "    if guide_response.status_code != 200:\n",
        "        print(f\"Failed to retrieve Parents Guide for {imdb_id}\")\n",
        "        return \"N/A\"\n",
        "\n",
        "    guide_soup = BeautifulSoup(guide_response.text, 'html.parser')\n",
        "\n",
        "    # Extract the 'Violence & Gore' rating\n",
        "    violence_section = guide_soup.find('span', text='Violence & Gore')\n",
        "    if violence_section:\n",
        "        violence_info = violence_section.find_next('span', {'class': 'ipl-status-pill'}).text.strip()\n",
        "        return violence_info\n",
        "    else:\n",
        "        return \"N/A\"\n",
        "\"\"\"\n",
        "\n",
        "def get_parents_guide_violence(imdb_id, headers):\n",
        "    base_url = f\"https://www.imdb.com/title/{imdb_id}/parentalguide\"\n",
        "    response = requests.get(base_url, headers=headers)\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Failed to retrieve Parents Guide for {imdb_id}\")\n",
        "        return \"N/A\"\n",
        "\n",
        "    guide_soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Locate the 'Violence & Gore' section by its ID\n",
        "    violence_section = guide_soup.find('section', {'id': 'advisory-violence'})\n",
        "\n",
        "    if not violence_section:\n",
        "        return \"N/A\"\n",
        "\n",
        "    # Look for the severity rating within the section (e.g., Mild, Moderate)\n",
        "    severity = violence_section.find('span', class_=lambda x: x and x.startswith('ipl-status-pill'))\n",
        "\n",
        "    return severity.text.strip() if severity else \"N/A\"\n",
        "\n",
        "\n",
        "def scrape_imdb_data(imdb_ids):\n",
        "    # List to store the scraped data\n",
        "    scraped_data = []\n",
        "\n",
        "    # Base URL for IMDb\n",
        "    base_url = \"https://www.imdb.com/title/\"\n",
        "\n",
        "    # Header to bypass IMDb's scraper block\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\"\n",
        "    }\n",
        "\n",
        "    for i in range(0, len(imdb_ids), 2):  # Gets 1 of every 2 entries because every element is doubled\n",
        "        # Create the URL for the IMDb page\n",
        "        url = base_url + imdb_ids[i]\n",
        "\n",
        "        # Send an HTTP GET request with headers to fetch the HTML content of the page\n",
        "        response = requests.get(url, headers=headers)\n",
        "\n",
        "        if response.status_code != 200:\n",
        "            print(f\"Failed to retrieve {imdb_ids[i]}\")\n",
        "            continue\n",
        "\n",
        "        #Ensure the encoding is UTF-8\n",
        "        response.encoding = 'utf-8'\n",
        "\n",
        "        # Parse the HTML content using BeautifulSoup\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Extract relevant data (example fields)\n",
        "        try:\n",
        "            # Get the title of the series\n",
        "            title = soup.find('h1').text.strip()\n",
        "\n",
        "\n",
        "            # Get the rating of the series (<span class=\"sc-eb51e184-1 ljxVSS\">6.5</span>)\n",
        "            rating_element = soup.find('span', {'class': 'sc-eb51e184-1 ljxVSS'})\n",
        "            rating = float(rating_element.text.strip()) if rating_element else \"N/A\"\n",
        "\n",
        "\n",
        "            #Get the amount of user ratings (<div class=\"sc-eb51e184-3 kgbSIj\">120</div>)\n",
        "            #rating_count = soup.find('span' , {'class': 'sc-eb51e184-3 kgbSIj'}).text.strip() if soup.find('span' , {'class': 'sc-eb51e184-3 kgbSIj'}) else \"0\"\n",
        "\n",
        "            # Get the amount of user ratings (<div class=\"sc-eb51e184-3 kgbSIj\">120</div>)\n",
        "            rating_count = soup.find('div', {'class': 'sc-eb51e184-3 kgbSIj'}).text.strip() if soup.find('div', {'class': 'sc-eb51e184-3 kgbSIj'}) else \"0\"\n",
        "\n",
        "            # Get the start date (if available)\n",
        "            release_date = soup.find('a', {'class': 'ipc-metadata-list-item__list-content-item ipc-metadata-list-item__list-content-item--link'}, href=lambda href: href and '/releaseinfo' in href)\n",
        "            release_date_text = release_date.text.strip() if release_date else \"N/A\"\n",
        "\n",
        "            # Get the number of episodes (if it's a series) (<span class=\"ipc-title__subtext\">44</span>)\n",
        "            #episodes = soup.find('span', {'class': 'ipc-title__subtext'}).text.strip() if soup.find('span', {'class': 'ipc-title__subtext'}) else \"N/A\"\n",
        "\n",
        "            # Get the number of episodes (if it's a series)\n",
        "            episodes_element = soup.find('h3', string=lambda text: text and \"Episodes\" in text)\n",
        "            episodes_text = episodes_element.find_next('span', class_='ipc-title__subtext').text.strip() if episodes_element else \"N/A\"\n",
        "            try:\n",
        "                episodes = int(episodes_text) if episodes_text.isdigit() else \"N/A\"\n",
        "            except ValueError:\n",
        "                episodes = \"N/A\"\n",
        "\n",
        "\n",
        "            # Get the parental certificate or guide\n",
        "            violence_rating = get_parents_guide_violence(imdb_ids[i], headers)\n",
        "\n",
        "            # Get the stars (actors) listed\n",
        "            stars_section = soup.find_all('a', href=lambda href: href and \"/name/\" in href)\n",
        "            stars = ', '.join([star.text.strip() for star in stars_section])  # (Not) limiting to the first 5 stars\n",
        "\n",
        "            # Get the production company info (if available)\n",
        "            #production_company = soup.find('a', {'class': 'ipc-metadata-list-item__list-content-item ipc-metadata-list-item__list-content-item--link'})\n",
        "            #production_company_name= production_company.text.strip() if production_company else \"N/A\"\n",
        "            production_company = soup.find('a', {'class': 'ipc-metadata-list-item__list-content-item ipc-metadata-list-item__list-content-item--link'}, href=lambda href: href and '/company/' in href)\n",
        "            production_company_name = production_company.text.strip() if production_company else \"N/A\"\n",
        "\n",
        "\n",
        "\n",
        "            # Add the scraped data to the list\n",
        "            scraped_data.append([imdb_ids[i], title, rating, rating_count, release_date_text, episodes, violence_rating, stars, production_company_name])\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error scraping {imdb_ids[i]}: {e}\")\n",
        "\n",
        "    return scraped_data\n",
        "\n",
        "def write_to_csv(scraped_data, output_file):\n",
        "    # Define the headers for the CSV file\n",
        "    headers = [\"IMDB_ID\", \"Title\", \"Rating\", \"Rating_Count\", \"Release_Date\", \"Episode_Count\", \"Violence\", \"Stars\", \"Production\"]\n",
        "\n",
        "    # Write the data to a CSV file\n",
        "    with open(output_file, 'w', newline='', encoding='utf-8') as file:\n",
        "        writer = csv.writer(file, delimiter=';')\n",
        "        # Write headers as a row\n",
        "        writer.writerow(headers)\n",
        "        # Write each entry in scraped_data as a separate row\n",
        "        for row in scraped_data:\n",
        "            # Ensure that ratings are formatted as floats with one decimal place\n",
        "            row[2] = f\"{float(row[2]):.1f}\" if row[2] != \"N/A\" else row[2]\n",
        "            writer.writerow(row)\n",
        "\n",
        "        \"\"\"\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow(headers)\n",
        "        writer.writerows(scraped_data)\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Example usage\n",
        "scraped_data = scrape_imdb_data(imdb_ids)\n",
        "write_to_csv(scraped_data, 'imdb_scraped_data_final.csv')\n"
      ],
      "metadata": {
        "id": "SZJMxfGdqsXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Check which files are present in the directory**"
      ],
      "metadata": {
        "id": "Xn0SQiaOhaj_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3p4ZtMyct8nz",
        "outputId": "cb6d0f73-98fb-4df2-87a2-8510e4c357c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['.config', '.ipynb_checkpoints', 'imdb_scraped_data.csv', 'fullhtmltext_filtered.txt', 'samplehtmltext.txt', 'sample_data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('imdb_scraped_data.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIrDMdee0cZp",
        "outputId": "ac870020-d51f-4a88-f3c4-626d6bd036f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_183d0f35-ba3c-4043-89c6-6d8238e89aaf\", \"imdb_scraped_data.csv\", 204097)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}